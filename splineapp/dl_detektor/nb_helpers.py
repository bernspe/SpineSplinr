
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/helpers.ipynb

from fastai.vision import *
from skimage.morphology import skeletonize

def predict_line(image, learn):
    prediction = learn.predict(image)[0]
    return mask_to_points(np.array(torch.squeeze(prediction.data)))

def read_image_from_dataframe(df, img):
    image = np.array(df[img].iloc[0], dtype=np.float32).reshape(500,500,3)
    image = np.swapaxes(np.swapaxes(image,0,2), 1,2)
    image = (image-np.min(image))/(np.max(image)-np.min(image))
    return Image(tensor(image))

def get_peaks(map_ori):
    from scipy.ndimage.filters import gaussian_filter
    thre1 = 0.2
    one_heatmap = gaussian_filter(map_ori, sigma=3)
    map_left = np.zeros(one_heatmap.shape)
    map_left[1:, :] = one_heatmap[:-1, :]
    map_right = np.zeros(one_heatmap.shape)
    map_right[:-1, :] = one_heatmap[1:, :]
    map_up = np.zeros(one_heatmap.shape)
    map_up[:, 1:] = one_heatmap[:, :-1]
    map_down = np.zeros(one_heatmap.shape)
    map_down[:, :-1] = one_heatmap[:, 1:]

    peaks_binary = np.logical_and.reduce(
        (one_heatmap >= map_left, one_heatmap >= map_right,
         one_heatmap >= map_up, one_heatmap >= map_down, one_heatmap > thre1))
    peaks = list(zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0]))  # note reverse
    peaks_with_score = [x + (map_ori[x[1], x[0]],) for x in peaks]
    peak_id = range(0, len(peaks))
    peaks_with_score_and_id = [peaks_with_score[i] + (peak_id[i],) for i in range(len(peak_id))]

    return np.array(peaks_with_score_and_id)

def predict_vertebrae_position(image, learn):
    vertebrae_positions = {}
    batch = learn.data.one_item(image)
    res = learn.pred_batch(batch=batch)
    for i, vertebrae in enumerate(vertebraes):
        vertebrae_positions[vertebrae] = None
        all_peaks_pred = get_peaks(res[0,i])
        if (len(all_peaks_pred) > 0):
            vertebrae_positions[vertebrae] = all_peaks_pred[np.argmax(all_peaks_pred[:,2]),0:2]
    return vertebrae_positions

vertebraes=['T1','T2','T3','T4','T5','T6','T7','T8','T9','T10','T11','T12','L1','L2','L3','L4','L5','S1']

def set_mask_for_label(input, label):
    i_l_mask = input == label
    input[i_l_mask] = 1
    input[~i_l_mask] = 0
    return input

def interpolate(path, num=20, debug=False):
    from scipy.interpolate import interp1d

    f = interp1d(path[:, 1], path[:, 0])
    x = np.linspace(path[:, 1].min(), path[:, 1].max(), num=num,
                    endpoint=True, dtype=np.float)
    x = np.round(x).astype(np.int)
    y = np.round(f(x)).astype(np.int)
    out = np.concatenate((np.reshape(x,(x.shape[0],1)),np.reshape(y,(y.shape[0],1))), axis=1)

    out[:, 0], out[:, 1] = out[:, 1], out[:, 0].copy()
    return out

def mask_to_points(inputs):
    points = {}
    labels = ["left", "right"]
    for label,l_name in enumerate(labels):
        input = set_mask_for_label(inputs.copy(), label+1)

        input_skel = skeletonize(input).astype(np.uint8)

        input_points = np.array(np.where(input_skel)).T
        input_points[:,0], input_points[:,1] = input_points[:,1], input_points[:,0].copy()

        if input_points[0,1] == input_points[1,1]:
            input_points[0,1] = input_points[0,1] - 1

        input_points_int = interpolate(input_points).tolist()
        points[l_name] = input_points_int
    return points


class waist_pixel_accuracy(LearnerCallback):
    _order=-20 # Needs to run before the recorder

    def __init__(self, learn):
        super().__init__(learn)

    def on_train_begin(self, **kwargs):
        self.learn.recorder.add_metric_names(['t_lw_p_ac', 't_rw_p_ac', 'v_lw_p_ac', 'v_rw_p_ac'])

    def on_batch_end(self, last_output, last_target, **kwargs):


        def label_pixel_accuracy(input, target, label):
            input, target = set_mask_for_label(input, target, label)

            same_fields = np.logical_and(target, input)
            ac = []
            for i in range(input.shape[0]):
                ac.append(len(np.where(same_fields[i] == 1)[0]) / len(np.where(target[i] == 1)[0]))

            #return tensor(np.array(ac).mean())
            return np.array(ac).mean()

        if kwargs['train'] == True:
            self.train_lw_acc.append(label_pixel_accuracy(last_output, last_target, lw_l))
            self.train_rw_acc.append(label_pixel_accuracy(last_output, last_target, rw_l))
        else:
            self.valid_lw_acc.append(label_pixel_accuracy(last_output, last_target, lw_l))
            self.valid_rw_acc.append(label_pixel_accuracy(last_output, last_target, rw_l))

    def on_epoch_begin(self, **kwargs):
        self.train_lw_acc = []
        self.train_rw_acc = []
        self.valid_lw_acc = []
        self.valid_rw_acc = []

    def on_epoch_end(self, last_metrics, **kwargs):

        return add_metrics(last_metrics, [np.array(self.train_lw_acc).mean(),
                                          np.array(self.train_rw_acc).mean(),
                                          np.array(self.valid_lw_acc).mean(),
                                          np.array(self.valid_rw_acc).mean()])

class waist_curve_accuracy(LearnerCallback):
    _order=-20 # Needs to run before the recorder

    def __init__(self, learn):
        super().__init__(learn)

    def on_train_begin(self, **kwargs):

        self.c_e = 0

        self.learn.recorder.add_metric_names(['t_lw_shift', 't_rw_shift',
                                              't_lw_er_proc', 't_rw_er_proc', 't_lw_er_after', 't_lw_er_after',
                                              't_lw_er_before', 't_rw_er_before',

                                              'v_lw_shift', 'v_rw_shift',
                                              'v_lw_er_proc', 'v_rw_er_proc', 'v_lw_er_after', 'v_rw_er_after',
                                              'v_lw_er_before', 'v_rw_er_before'])

    def on_batch_end(self, last_output, last_target, **kwargs):

        def label_curve_accuracy(input, target, label):
            input, target = set_mask_for_label(input, target, label)

            ers=[]
            translations=[]
            er_before=[]
            er_after=[]



            for i in range(input.shape[0]):
                try:
                    input_skel = skeletonize(input[i]).astype(np.uint8)
                    target_skel = skeletonize(target[i]).astype(np.uint8)

                    input_points = np.array(np.where(input_skel)).T
                    input_points[:,0], input_points[:,1] = input_points[:,1], input_points[:,0].copy()

                    target_points = np.array(np.where(target_skel)).T
                    target_points[:,0], target_points[:,1] = target_points[:,1], target_points[:,0].copy()

                    if input_points[0,1] == input_points[1,1]:
                        input_points[0,1] = input_points[0,1] - 1

                    if target_points[0,1] == target_points[1,1]:
                        target_points[0,1] = target_points[0,1] - 1


                    input_points_int = interpolate(input_points)

                    target_points_int = interpolate(target_points)

                    er, input_trans, trans = procrustes_analysis(target_points_int, input_points_int)

                    ers.append(er)
                    translations.append(np.linalg.norm(trans['translation']))
                    er_after.append(np.abs(input_trans - target_points_int).mean())
                    er_before.append(np.abs(input_points_int - target_points_int).mean())
                except:
                    continue


            return np.array(ers).mean(), np.array(translations).mean(), np.array(er_after).mean(), np.array(er_before).mean()


        er_pr_lw, trans_lw, er_after_lw, er_before_lw = label_curve_accuracy(last_output, last_target, lw_l)
        er_pr_rw, trans_rw, er_after_rw, er_before_rw = label_curve_accuracy(last_output, last_target, rw_l)


        if kwargs['train'] == True:
            self.t_lw_shift.append(trans_lw)
            self.t_rw_shift.append(trans_rw)
            self.t_lw_er_proc.append(er_pr_lw)
            self.t_rw_er_proc.append(er_pr_rw)
            self.t_lw_er_after.append(er_after_lw)
            self.t_rw_er_after.append(er_after_rw)
            self.t_lw_er_before.append(er_before_lw)
            self.t_rw_er_before.append(er_before_rw)
        else:
            self.v_lw_shift.append(trans_lw)
            self.v_rw_shift.append(trans_rw)
            self.v_lw_er_proc.append(er_pr_lw)
            self.v_rw_er_proc.append(er_pr_rw)
            self.v_lw_er_after.append(er_after_lw)
            self.v_rw_er_after.append(er_after_rw)
            self.v_lw_er_before.append(er_before_lw)
            self.v_rw_er_before.append(er_before_rw)


    def on_epoch_begin(self, **kwargs):
        self.t_lw_shift = []
        self.t_rw_shift = []
        self.t_lw_er_proc = []
        self.t_rw_er_proc = []
        self.t_lw_er_after = []
        self.t_rw_er_after = []
        self.t_lw_er_before = []
        self.t_rw_er_before = []

        self.v_lw_shift = []
        self.v_rw_shift = []
        self.v_lw_er_proc = []
        self.v_rw_er_proc = []
        self.v_lw_er_after = []
        self.v_rw_er_after = []
        self.v_lw_er_before = []
        self.v_rw_er_before = []


    def on_epoch_end(self, last_metrics, **kwargs):
        if self.c_e % 10 == 0:
            filename = 'stage-resnet34-256-16-'+ str(self.c_e)
            self.save(filename)
            print(filename,"saved")

        self.c_e += 1

        return add_metrics(last_metrics, [np.array(self.t_lw_shift).mean(),
                                          np.array(self.t_rw_shift).mean(),
                                          np.array(self.t_lw_er_proc).mean(),
                                          np.array(self.t_rw_er_proc).mean(),
                                          np.array(self.t_lw_er_after).mean(),
                                          np.array(self.t_rw_er_after).mean(),
                                          np.array(self.t_lw_er_before).mean(),
                                          np.array(self.t_rw_er_before).mean(),

                                          np.array(self.v_lw_shift).mean(),
                                          np.array(self.v_rw_shift).mean(),
                                          np.array(self.v_lw_er_proc).mean(),
                                          np.array(self.v_rw_er_proc).mean(),
                                          np.array(self.v_lw_er_after).mean(),
                                          np.array(self.v_rw_er_after).mean(),
                                          np.array(self.v_lw_er_before).mean(),
                                          np.array(self.v_rw_er_before).mean()])



def o_p_acc(input, target):
    target_squeeze = target.squeeze(1)
    out = (input.argmax(dim=1) == target_squeeze).float().mean()
    return out

def heatmap_gen(x,y, shape):

    #DEFINE GRID SIZE AND RADIUS(h)
    grid_size=1
    h=10

    #FUNCTION TO CALCULATE INTENSITY WITH QUARTIC KERNEL
    def kde_quartic(d,h):
        dn=d/h
        P=(15/16)*(1-dn**2)**2
        return P

    def kde_linear(d,h):
        return 1-(d/h)


    #PROCESSING
    itensity = np.zeros(shape, dtype=np.float32)

    if x-h < 0:
        h = h - abs(x-h)

    if y-h < 0:
        h = h - abs(y-h)

    if x+h > shape[0]:
        h = h - ((x+h)-shape[0])

    if y+h > shape[1]:
        h = h - ((y+h)-shape[1])

    for x_p in range(x-h, x+h):
        for y_p in range(y-h, y+h):
            d=math.sqrt((x_p-x)**2+(y_p-y)**2)
            if d<=h:
                p=kde_quartic(d,h)
            else:
                p=0
            itensity[x_p,y_p] = p

    #HEATMAP OUTPUT
    return itensity

class HeatLoss_4(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, input, target):
        m = (target > 0.0)
        m2 = (target > 0.0)

        for dset in range(input.shape[0]):
            for i in range(len(vertebraes)):
                c = torch.cat((m2[dset,:i,:,:],m2[dset,(i+1):,:,:]))
                logor = torch.zeros((c.shape[1], c.shape[2]), dtype=torch.uint8).cuda()
                for d in c:
                    logor = logor | d
                m[dset,i,:,:] = logor

        ret = torch.abs(input[m] - target[m])
        ret2 = torch.abs(input[m2] - target[m2])

        mean = torch.mean(ret)
        mean2 = torch.mean(ret2)
        print("Mean Neg:",mean.item(),"Mean Pos:",mean2.item(),end="\r")

        return (mean+mean2)/2

class verta_pos_abs_error(LearnerCallback):
    _order=-20 # Needs to run before the recorder

    def __init__(self, learn):
        super().__init__(learn)

    def on_train_begin(self, **kwargs):
        self.c_e = 0

        self.learn.recorder.add_metric_names(["all_t", "all_v", "false_pos_rate_t", "false_pos_rate_v",
                                              "false_neg_rate_t", "false_neg_rate_v"])
        for verta in vertebraes:
            self.learn.recorder.add_metric_names([verta+"_t"])
            self.learn.recorder.add_metric_names([verta+"_v"])

    def on_batch_end(self, last_output, last_target, **kwargs):


        def get_peaks(map_ori):
            thre1 = 0.2
            one_heatmap = gaussian_filter(map_ori, sigma=3)
            map_left = np.zeros(one_heatmap.shape)
            map_left[1:, :] = one_heatmap[:-1, :]
            map_right = np.zeros(one_heatmap.shape)
            map_right[:-1, :] = one_heatmap[1:, :]
            map_up = np.zeros(one_heatmap.shape)
            map_up[:, 1:] = one_heatmap[:, :-1]
            map_down = np.zeros(one_heatmap.shape)
            map_down[:, :-1] = one_heatmap[:, 1:]

            peaks_binary = np.logical_and.reduce(
                (one_heatmap >= map_left, one_heatmap >= map_right,
                 one_heatmap >= map_up, one_heatmap >= map_down, one_heatmap > thre1))
            peaks = list(zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0]))  # note reverse
            peaks_with_score = [x + (map_ori[x[1], x[0]],) for x in peaks]
            peak_id = range(0, len(peaks))
            peaks_with_score_and_id = [peaks_with_score[i] + (peak_id[i],) for i in range(len(peak_id))]

            return np.array(peaks_with_score_and_id)

        def evaluate_results(output, target, verta_id):
            d = []
            #pdb.set_trace()
            for dset in range(output.shape[0]):
                if kwargs['train']:
                    self.all_count_t += 1
                else:
                    self.all_count_v += 1

                all_peaks_pred = get_peaks(np.array(output[dset,verta_id]))
                all_peaks_target = get_peaks(np.array(target[dset,verta_id]))

                if (len(all_peaks_target) == 0) and (len(all_peaks_pred) == 0):
                    d.append(0)
                    continue

                if ((len(all_peaks_target) == 0) and (len(all_peaks_pred) > 0)):
                    if kwargs['train']:
                        self.false_positives_t += 1
                    else:
                        self.false_positives_v += 1
                    continue

                if ((len(all_peaks_target) > 0) and (len(all_peaks_pred) == 0)):
                    if kwargs['train']:
                        self.false_negatives_t += 1
                    else:
                        self.false_negatives_v += 1
                    continue

                peak_pred = all_peaks_pred[np.argmax(all_peaks_pred[:,2]),0:2]
                peak_target = all_peaks_target[np.argmax(all_peaks_target[:,2]),0:2]
                d.append(math.sqrt((peak_pred[0]-peak_target[0])**2+(peak_pred[1]-peak_target[1])**2))

            if len(d) == 0:
                return 0
            else:
                return np.array(d).mean()


        #pdb.set_trace()
        if kwargs['train'] == True:
            for i,verta in enumerate(vertebraes):
                self.train_vertas[verta+"_t"].append(evaluate_results(last_output, last_target, i))
        else:
            for i,verta in enumerate(vertebraes):
                self.valid_vertas[verta+"_v"].append(evaluate_results(last_output, last_target, i))



    def on_epoch_begin(self, **kwargs):
        self.false_positives_t = 0
        self.false_positives_v = 0
        self.false_negatives_t = 0
        self.false_negatives_v = 0
        self.all_count_t = 0
        self.all_count_v = 0
        self.train_vertas = {}
        self.valid_vertas = {}
        for verta in vertebraes:
            self.train_vertas[verta+"_t"] = []
            self.valid_vertas[verta+"_v"] = []

    def on_epoch_end(self, last_metrics, **kwargs):

        if self.c_e % 10 == 0:
            filename = 'unet-heatmap-net-batch-'+ str(self.c_e)
            self.save(filename)

        self.c_e += 1

        metrics = []

        all_t = []
        all_v = []
        for verta in vertebraes:
            all_t.append(np.array(self.train_vertas[verta + "_t"]).mean())
            all_v.append(np.array(self.valid_vertas[verta + "_v"]).mean())

        metrics.append(np.array(all_t).mean())
        metrics.append(np.array(all_v).mean())

        metrics.append((self.false_positives_t / self.all_count_t))
        metrics.append((self.false_positives_v / self.all_count_v))

        metrics.append((self.false_negatives_t / self.all_count_t))
        metrics.append((self.false_negatives_v / self.all_count_v))

        for verta in vertebraes:
            metrics.append(np.array(self.train_vertas[verta + "_t"]).mean())
            metrics.append(np.array(self.valid_vertas[verta + "_v"]).mean())

        return add_metrics(last_metrics, metrics)