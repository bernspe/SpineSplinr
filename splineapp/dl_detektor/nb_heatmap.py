
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/heatmap_unet_helpers.ipynb

import fastai
from fastai.vision import *
#from fastai.callbacks import *
#from fastai.utils.mem import *
import pdb
import numpy as np
#from matplotlib import pyplot as plt
from scipy.ndimage.filters import gaussian_filter
from PIL import Image as PILImage
from ipywidgets import IntProgress
from IPython.display import display
import matplotlib.pyplot as plt
import os
from random import *
from fastai.callbacks.hooks import *
from fastai.vision.learner import cnn_config
from fastai.vision.models.unet import _get_sfs_idxs, UnetBlock
from fastai.distributed import *

# define heatmaps
#heat_names=['T1','T2','T3','T4','T5','T6','T7','T8','T9','T10','T11','T12','L1','L2','L3','L4','L5','S1']
#heat_sizes=[ 16,  16,  16,  18,  18,  18,  20,  20,  22,  22,   24,   24,   26,  26,  28,  30,  32,  32]

heat_names=['T1','T2','T3','T4','T5','T6','T7','T8','T9','T10','T11','T12','L1','L2','L3','L4','L5']
heat_names_T12=['T12']
heat_sizes=[ 16,  16,  16,  18,  18,  18,  20,  20,  22,  22,   24,   24,   26,  26,  28,  30,  32]
heat_sizes_T12=[24]

# define paths
boostnet_training_labels_file = Path("/home/vr/johannes/scoliosis_lib/xraydata/boostnet_labeldata/labels/training/all_centroids.pickle")
boostnet_test_labels_file = Path("/home/vr/johannes/scoliosis_lib/xraydata/boostnet_labeldata/labels/test/all_centroids.pickle")
data_folder = Path("/home/vr/johannes/scoliosis_lib/xraydata/netdata/")
path_img = data_folder/"images"
#path_heat = data_folder/"labels"/"heatmaps"
# points
analyzers=['carl','peter', 'marlene', "wadim"]
parquet_file = "/home/vr/johannes/scoliosis_lib/xraydata/xray-complete.parquet"
no_valid_image_files = ["7NEIRRHF", "C8915RQL", "F3W6HWAH", "F8U46BGH", "MJ3TQER8", "RJ4FH75L", "V79GMU86"]
nn_variants_file_full =  Path("/home/vr/johannes/scoliosis_lib/xraydata/nn_variants.csv")
nn_variants_file_1 =  Path("/home/vr/johannes/scoliosis_lib/xraydata/nn_variants_1.csv")
nn_variants_file_2 =  Path("/home/vr/johannes/scoliosis_lib/xraydata/nn_variants_2.csv")
nn_variants_file_3 =  Path("/home/vr/johannes/scoliosis_lib/xraydata/nn_variants_3.csv")
chexnet_path = "/home/vr/johannes/scoliosis_lib/CheXNet-master/model.pth.tar"
cropp_x_min = 150
cropp_x_max = 350
thres_drop_labeler = 10

def size_image(image,t_size = (500,200)):
    y_s = image.size[0]
    x_s = image.size[1]
    img_sized = image.apply_tfms([],size=(t_size[0],round(x_s/(y_s/t_size[0]))))
    if img_sized.size[1] > t_size[1]:
        gap = int((img_sized.data.shape[2] - t_size[1])/2)
        cropp_min = gap
        cropp_max = img_sized.data.shape[2] - gap - t_size[1]
        img_sized_new = Image(img_sized.data[:,:,gap:-cropp_max])
    elif img_sized.size[1] < t_size[1]:
        img_sized_new = torch.zeros((3,t_size[0],t_size[1]),dtype=torch.float32)
        start_x = int((t_size[1]/2) - (img_sized.data.shape[2]/2))
        img_sized_new[:,:,start_x:start_x+img_sized.data.shape[2]] = img_sized.data
        img_sized_new = Image(img_sized_new)
    elif img_sized.size[1] == t_size[1]:
        img_sized_new = img_sized
    return img_sized_new

# load state dict from CheXNet model
def copy_state_dict_over(from_body, to_body):
    body_par = list(to_body.named_parameters())

    for n, p in body_par:

        key = 'module.densenet121.features.' + n[2:]

        conv = key.find(".conv")
        norm = key.find(".norm")
        rep = conv if conv != -1 else norm
        rep = -1 if ((key.find("conv0.weight") != -1) or
                     (key.find("norm0.weight") != -1) or
                     (key.find("norm0.bias") != -1) or
                     (key.find("norm5.weight") != -1) or
                     (key.find("norm5.bias") != -1) or
                     (key.find("transition") != -1)) else rep

        key = (key[:rep+5] + "."+ key[rep+5:]) if rep != -1 else key

        c = from_body["state_dict"][key]

        if np.sum(np.array(c.shape) - np.array(p.data.shape)) != 0:
            print("Not same shape in ", key)

        p.data = c

    return to_body

def densenet_split(m):
    return (m[0][6],m[1])

def dense_unet_learner(data, arch, pretrained=False, use_chexnet=True, blur_final=True,
                 norm_type=None, split_on=None, blur=False,
                 self_attention=False, y_range=None, last_cross=True,
                 bottle=False, cut=None, **learn_kwargs:Any):

   # pdb.set_trace()
    meta = cnn_config(arch)
    body = create_body(arch, pretrained, cut)

    if use_chexnet:
        chexnet = torch.load(chexnet_path)
        copy_state_dict_over(chexnet, body)

    body = body[0].cpu()

    body = nn.Sequential(body[0], body[1], body[2], body[3], body[4],
                         body[5:7],
                         body[7:9],
                         body[9:])

    try:    size = data.train_ds[0][0].size
    except: size = next(iter(data.train_dl))[0].shape[-2:]

    model = dense_DynamicUnet(body, n_classes=data.c, img_size=size, blur=blur, blur_final=blur_final,
          self_attention=self_attention, y_range=y_range, norm_type=norm_type, last_cross=last_cross,
          bottle=bottle)

    model = to_device(model, data.device)

    learn = Learner(data, model, **learn_kwargs)
    learn.split(densenet_split)
    if pretrained: learn.freeze()
    apply_init(model[2], nn.init.kaiming_normal_)
    return learn

class dense_DynamicUnet(SequentialEx):
    "Create a U-Net from a given architecture."
    def __init__(self, encoder:nn.Module, n_classes:int, img_size:Tuple[int,int]=(256,256), blur:bool=False, blur_final=True, self_attention:bool=False,
                 y_range:Optional[Tuple[float,float]]=None,
                 last_cross:bool=True, bottle:bool=False, **kwargs):

        imsize = img_size
        sfs_szs = model_sizes(encoder, size=imsize)
        sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))
        self.sfs = hook_outputs([encoder[i] for i in sfs_idxs], detach=False)
        x = dummy_eval(encoder, imsize).detach()

        ni = sfs_szs[-1][1]
        middle_conv = nn.Sequential(conv_layer(ni, ni*2, **kwargs),
                                    conv_layer(ni*2, ni, **kwargs)).eval()
        x = middle_conv(x)
        layers = [encoder, batchnorm_2d(ni), nn.ReLU(), middle_conv]

        for i,idx in enumerate(sfs_idxs):
            not_final = i!=len(sfs_idxs)-1
            up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])
            do_blur = blur and (not_final or blur_final)
            sa = self_attention and (i==len(sfs_idxs)-3)
            unet_block = UnetBlock(up_in_c, x_in_c, self.sfs[i], final_div=not_final, blur=do_blur, self_attention=sa,
                                   **kwargs).eval()
            layers.append(unet_block)
            x = unet_block(x)

        ni = x.shape[1]
        if imsize != sfs_szs[0][-2:]: layers.append(PixelShuffle_ICNR(ni, **kwargs))
        x = PixelShuffle_ICNR(ni)(x)
        if imsize != x.shape[-2:]: layers.append(Lambda(lambda x: F.interpolate(x, imsize, mode='nearest')))
        if last_cross:
            layers.append(MergeLayer(dense=True))
            ni += in_channels(encoder)
            layers.append(res_block(ni, bottle=bottle, **kwargs))
        layers += [conv_layer(ni, n_classes, ks=1, use_activ=False, **kwargs)]
        if y_range is not None: layers.append(SigmoidRange(*y_range))
        super().__init__(*layers)

def move_x_points(an_dict):
    for key in an_dict.keys():
        for verta in an_dict[key][heat_names]:
            for entry in an_dict[key][verta]:
                if type(entry) == np.ndarray:
                    entry[0] -= cropp_x_min
    return an_dict

def centroid(points):
    x_coords = [p[0] for p in points]
    y_coords = [p[1] for p in points]
    _len = len(points)
    centroid_x = sum(x_coords)/_len
    centroid_y = sum(y_coords)/_len
    return [centroid_x, centroid_y]

def prepare_images(an_dict):

    images = pd.read_parquet(parquet_file)

    progress = IntProgress(
        value=0,
        min=0,
        max=len(images.keys()),
        step=1,
        description='Loading:',
        bar_style='info',
        orientation='horizontal'
    )
    display(progress)
    progress.value = 0

    all_im_count = 0
    valid_im_count = 0
    for key in images.keys():
        if (key not in no_valid_image_files):

            all_im_count += 1
            labels_available = False
            for labeler in an_dict.keys():
                try:
                    d = np.array(an_dict[labeler].iloc[an_dict[labeler].index.get_loc(key)][heat_names])
                    d = d[0] if len(d) == 2 else d
                    for d_i in d:
                        if (type(d_i) != np.ndarray) and (type(d_i) != float):
                            print(type(d_i))
                    labels_available = True
                    break
                except KeyError:
                    pass

            if labels_available:
                valid_im_count += 1
                im = np.array(images[key].iloc[0],dtype=np.uint8).reshape((500,500,3))
                PILImage.fromarray(im[:,cropp_x_min:cropp_x_max,:]).save(path_img/(key+".png"))
            else:
                print("for file'",key,"' there are no labels available")
            progress.value += 1

    print("All image count", all_im_count)
    print("valid image count", valid_im_count)

def get_valid_labelers(all_vertas, fallback):
    # get indecies of valid labelers
    if len(all_vertas) == 1:
        return np.array([0])

    if len(all_vertas) == 2:
        iterator = zip(all_vertas[0], all_vertas[1])
        dists = [[0,1,[]]]

    if len(all_vertas) == 3:
        iterator = zip(all_vertas[0], all_vertas[1], all_vertas[2])
        dists = [[0,1,[]],[0,2,[]],[1,2,[]]]

    if len(all_vertas) == 4:
        iterator = zip(all_vertas[0], all_vertas[1], all_vertas[2], all_vertas[3])
        dists = [[0,1,[]],[0,2,[]],[0,3,[]],[1,2,[]],[1,3,[]],[2,3,[]]]

    for verta in iterator:

        abort = False
        for i in range(len(verta)):
            if type(verta[i]) == float:
                abort = True
                break

        if abort:
            continue

        for dist in dists:
            dist[2].append(distance(verta[dist[0]], verta[dist[1]]))

    for dist in dists:
        dist[2] = np.array(dist[2]).mean()

    dists = np.array(dists)

    if (len(all_vertas) == 2) and (len(np.where((dists[:,2] < thres_drop_labeler) == False)[0]) > 0):
        valid_labels = np.array([fallback]) if fallback != -1 else np.array([0])
    else:
        valid_labels =  dists[dists[:,2] < thres_drop_labeler][:,0:2]

    if len(valid_labels) == 0:
        valid_labels = np.array([fallback]) if fallback != -1 else np.array([0])

    if len(valid_labels) == 2:
        valid_labels = valid_labels if len(np.intersect1d(valid_labels[0],valid_labels[1])) > 0 else valid_labels[0]

    return np.unique(valid_labels).astype(np.int)


def calc_verta_mean(valid_labelers, all_vertas):
    new_verta_poses = [math.nan for i in range(len(heat_names))]
    for heat in range(len(heat_names)):
        t_verta_pos = []

        for labeler in valid_labelers:
            if type(all_vertas[labeler][heat]) != float:
                t_verta_pos.append(all_vertas[labeler][heat])
        if len(t_verta_pos) > 0:
            new_verta_poses[heat] = np.round(np.mean(np.array(t_verta_pos), axis=0)).astype(np.int)
    return new_verta_poses

def refina_labels(image, an_dict, valid):

    fallback = -1
    all_vertas = []
    for i,ana in enumerate(an_dict.keys()):
        try:
            #pdb.set_trace()
            d = np.array(an_dict[ana].iloc[an_dict[ana].index.get_loc(image)][heat_names])
            d = d[0] if len(d) == 2 else d

            abort = True
            for d_i in d:
                if type(d_i) != float:
                    abort = False
                    break;

            if abort:
                print("for image",image,"and analyzer",ana,"are no labels")
                continue

            '''
            # offset x-pos in fact of cropping
            for entry in d:
                if type(entry) != float:
                    entry[0] -= cropp_x_min
            '''


            #pdb.set_trace()
            all_vertas.append(d)
            if ana == "peter":
                fallback = i
        except:
            continue

    #print(image, len(all_vertas))
    if (len(all_vertas) == 0):
        pdb.set_trace()

    #if not valid:
        #return all_vertas
    #else:
    #print (all_vertas)

    valid_labelers = get_valid_labelers(all_vertas, fallback)
    return calc_verta_mean(valid_labelers, all_vertas)

class HeatLoss(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, input, target):
        m = (target > 0.0)
        m2 = (target > 0.0)

        for dset in range(input.shape[0]):
            for i in range(len(heat_names)):
                c = torch.cat((m2[dset,:i,:,:],m2[dset,(i+1):,:,:]))
                logor = torch.zeros((c.shape[1], c.shape[2]), dtype=torch.uint8).cuda()
                for d in c:
                    logor = logor | d
                m[dset,i,:,:] = logor

        ret = torch.abs(input[m] - target[m])
        ret2 = torch.abs(input[m2] - target[m2])

        mean = torch.mean(ret)
        mean2 = torch.mean(ret2)
        #print("Mean Neg:",mean.item(),"Mean Pos:",mean2.item(),end="\r")

        return (mean+mean2)/2

class HeatLoss_3(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, input, target):
        m = (target > 0.0)# mask for other vertebra
        m2 = (target > 0.0) # mask for specific vertebra
        m4 = (target > 0.0)# mask for neighborhood vertebras
        m3 = 1 - m2 # mask for background

        for dset in range(input.shape[0]):
            for i in range(len(heat_names)):

                c = torch.cat((m2[dset,:i,:,:],m2[dset,(i+1):,:,:]))
                logor = torch.zeros((c.shape[1], c.shape[2]), dtype=torch.uint8).cuda()

                for d in c:
                    logor = logor | d

                m[dset,i,:,:] = logor
                m3[dset,i,:,:] = 1 - (logor | m2[dset,i,:,:])

                if i == 0:
                     m4[dset,i,:,:] = m2[dset,i+1,:,:]

                if i == (len(heat_names)-1):
                     m4[dset,i,:,:] = m2[dset,i-1,:,:]

                if (i>0) and (i<(len(heat_names)-1)):
                    m4[dset,i,:,:] = m2[dset,i-1,:,:] | m2[dset,i+1,:,:]



        ret = torch.abs(input[m] - target[m])
        ret2 = torch.abs(input[m2] - target[m2])
        ret3 = torch.abs(input[m3] - target[m3])
        ret4 = torch.abs(input[m4] - target[m4])

        mean = torch.mean(ret)
        mean2 = torch.mean(ret2)
        mean3 = torch.mean(ret3)
        mean4 = torch.mean(ret4)
        print("xspecific verta: %.4f" % mean2.item(),
              "xno vertas: %.4f" % mean3.item(),
              "xother vertas: %.4f" % mean.item(),
              "xneighborhood vertas: %.4f" % mean4.item(), end="\r")

        return (mean+mean2+mean3+mean4)/4

class HeatLoss_SIMPLE(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, input, target):
        ret = torch.abs(input - target)
        mean = torch.mean(ret)
        print("loss:",mean.item(), end="\r")
        return mean

class HeatLoss_0(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, input, target):
        #pdb.set_trace()
        m = (target > 0.0)
        m2 = 1-m

        ret = torch.abs(input[m] - target[m])
        ret2 = torch.abs(input[m2] - target[m2])

        mean = torch.mean(ret)
        mean2 = torch.mean(ret2)

        print("specific vertebra:",mean.item(), "background:",mean2.item(), end="\r")


        return (mean+mean2)/2

class HeatLoss_2(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, input, target):
        m = (target > 0.0)
        m2 = (target > 0.0)
        m3 = 1 - m2

        for dset in range(input.shape[0]):
            for i in range(len(heat_names)):
                c = torch.cat((m2[dset,:i,:,:],m2[dset,(i+1):,:,:]))
                logor = torch.zeros((c.shape[1], c.shape[2]), dtype=torch.uint8).cuda()
                for d in c:
                    logor = logor | d
                m[dset,i,:,:] = logor
                m3[dset,i,:,:] = 1 - (logor | m2[dset,i,:,:])


        ret = torch.abs(input[m] - target[m])
        ret2 = torch.abs(input[m2] - target[m2])
        ret3 = torch.abs(input[m3] - target[m3])

        mean = torch.mean(ret)
        mean2 = torch.mean(ret2)
        mean3 = torch.mean(ret3)
        print("specific verta:",mean2.item(), "other vertas:",mean.item(), "no vertas:",mean3.item(), end="\r")

        return (mean+mean2+mean3)/3

class HeatsProcessor(PreProcessor):
    "`PreProcessor` that stores the number of targets (heatmaps)."
    def __init__(self, ds:ItemList):
        self.c = ds.items[0][0].shape[0]
    def process(self, ds:ItemList):
        ds.c = self.c

class HeatsLabelList_T12(ItemList):
    "`ItemList` for heat maps."
    _processor = HeatsProcessor
    def __init__(self, items:Iterator, **kwargs):
        super().__init__(items, **kwargs)
        self.loss_func = HeatLoss_0()

    def get(self, i):
        o = super().get(i)

        try:
            if o[2]:
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]), o[2])
            else:
                for p,s in zip(o[0], heat_sizes):
                    max_shift = int(s/2)-2
                    x_shift = randint(-max_shift, max_shift)
                    y_shift = randint(-max_shift, max_shift)
                    p[0] += x_shift
                    p[1] += y_shift
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]), o[2])
        except:
            pdb.set_trace()
            print("exception")

    def analyze_pred(self, pred, thresh:float=0.5):
        return pred

    def reconstruct(self, t, x):
        return HeatMaps(t)

    @classmethod
    def from_list(cls, labellist, **kwargs):
        return cls(imagelist, **kwargs)

class HeatsLabelList_SIMPLE(ItemList):
    "`ItemList` for heat maps."
    _processor = HeatsProcessor
    def __init__(self, items:Iterator, **kwargs):
        super().__init__(items, **kwargs)
        self.loss_func = HeatLoss_SIMPLE()

    def get(self, i):
        o = super().get(i)

        try:

            if o[2]:
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))
            else:

                '''
                for p,s in zip(o[0], heat_sizes):
                    if type(p) != float:
                        max_shift = 3
                        x_shift = randint(-max_shift, max_shift)
                        y_shift = randint(-max_shift, max_shift)
                        p[0] += x_shift
                        p[1] += y_shift
                '''
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))
        except:
            pdb.set_trace()
            print("exception_0")

    def analyze_pred(self, pred, thresh:float=0.5):
        return pred

    def reconstruct(self, t, x):
        return HeatMaps(t)

    @classmethod
    def from_list(cls, labellist, **kwargs):
        return cls(imagelist, **kwargs)

class HeatsLabelList_0(ItemList):
    "`ItemList` for heat maps."
    _processor = HeatsProcessor
    def __init__(self, items:Iterator, **kwargs):
        super().__init__(items, **kwargs)
        self.loss_func = HeatLoss_0()

    def get(self, i):
        o = super().get(i)

        try:

            if o[2]:
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))
            else:

                '''
                for p,s in zip(o[0], heat_sizes):
                    if type(p) != float:
                        max_shift = 3
                        x_shift = randint(-max_shift, max_shift)
                        y_shift = randint(-max_shift, max_shift)
                        p[0] += x_shift
                        p[1] += y_shift
                '''
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))
        except:
            pdb.set_trace()
            print("exception_0")

    def analyze_pred(self, pred, thresh:float=0.5):
        return pred

    def reconstruct(self, t, x):
        return HeatMaps(t)

    @classmethod
    def from_list(cls, labellist, **kwargs):
        return cls(imagelist, **kwargs)

class HeatsLabelList_3(ItemList):
    "`ItemList` for heat maps."
    _processor = HeatsProcessor
    def __init__(self, items:Iterator, **kwargs):
        super().__init__(items, **kwargs)
        self.loss_func = HeatLoss_3()

    def get(self, i):
        o = super().get(i)

        try:
            if o[2]:
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))
            else:
                '''
                for p,s in zip(o[0], heat_sizes):
                    if type(p) != float:
                        max_shift = int(s/2)-2
                        x_shift = randint(-max_shift, max_shift)
                        y_shift = randint(-max_shift, max_shift)
                        p[0] += x_shift
                        p[1] += y_shift
                '''
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))


        except:
            pdb.set_trace()
            print("exception_3")

    def analyze_pred(self, pred, thresh:float=0.5):
        return pred

    def reconstruct(self, t, x):
        return HeatMaps(t)

    @classmethod
    def from_list(cls, labellist, **kwargs):
        return cls(imagelist, **kwargs)

class HeatsLabelList_2(ItemList):
    "`ItemList` for heat maps."
    _processor = HeatsProcessor
    def __init__(self, items:Iterator, **kwargs):
        super().__init__(items, **kwargs)
        self.loss_func = HeatLoss_2()

    def get(self, i):
        o = super().get(i)

        try:
            if o[2]:
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))
            else:
                '''
                for p,s in zip(o[0], heat_sizes):
                    if type(p) != float:
                        max_shift = int(s/2)-2
                        x_shift = randint(-max_shift, max_shift)
                        y_shift = randint(-max_shift, max_shift)
                        p[0] += x_shift
                        p[1] += y_shift
                '''
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))

        except:
            pdb.set_trace()
            print("exception_2")

    def analyze_pred(self, pred, thresh:float=0.5):
        return pred

    def reconstruct(self, t, x):
        return HeatMaps(t)

    @classmethod
    def from_list(cls, labellist, **kwargs):
        return cls(imagelist, **kwargs)

class HeatsLabelList(ItemList):
    "`ItemList` for heat maps."
    _processor = HeatsProcessor
    def __init__(self, items:Iterator, **kwargs):
        super().__init__(items, **kwargs)
        self.loss_func = HeatLoss()

    def get(self, i):
        o = super().get(i)

        try:
            if o[2]:
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))
            else:
                '''
                for p,s in zip(o[0], heat_sizes):
                    if type(p) != float:
                        max_shift = int(s/2)-2
                        x_shift = randint(-max_shift, max_shift)
                        y_shift = randint(-max_shift, max_shift)
                        p[0] += x_shift
                        p[1] += y_shift
                '''
                return HeatMaps(torch.stack([heatmap_gen(p,o[1], int(s/2)) for p,s in zip(o[0], heat_sizes)]))

        except:
            pdb.set_trace()
            print("exception_")

    def analyze_pred(self, pred, thresh:float=0.5):
        return pred

    def reconstruct(self, t, x):
        return HeatMaps(t)

    @classmethod
    def from_list(cls, labellist, **kwargs):
        return cls(imagelist, **kwargs)

def heatmap_gen(pt, shape, h):

    if type(shape) == int:
        shape = [shape, shape]

    #DEFINE GRID SIZE AND RADIUS(h)
    grid_size=1

    #FUNCTION TO CALCULATE INTENSITY WITH QUARTIC KERNEL
    def kde_quartic(d,h):
        dn=d/h
        P=(15/16)*(1-dn**2)**2
        return P

    def kde_linear(d,h):
        return 1-(d/h)


    #PROCESSING
    itensity = torch.zeros(shape, dtype=torch.float32)



    if (type(pt) != float) and (type(pt) != np.ndarray):
        print(type(pt))

    if ((type(pt) == float) or (type(pt) == np.float64)):
        return itensity

    try:
        if pt[1]-h < 0:
            h = h - abs(pt[1]-h)

        if pt[0]-h < 0:
            h = h - abs(pt[0]-h)

        if pt[1]+h > shape[0]:
            h = h - ((pt[1]+h)-shape[0])

        if pt[0]+h > shape[1]:
            h = h - ((pt[0]+h)-shape[1])

        for x_p in range(pt[1]-h, pt[1]+h):
            for y_p in range(pt[0]-h, pt[0]+h):
                d=math.sqrt((x_p-pt[1])**2+(y_p-pt[0])**2)
                if d<=h:
                    itensity[x_p,y_p] = kde_linear(d,h)
    except:
        pdb.set_trace()
        print("exception")

    #HEATMAP OUTPUT

    return itensity

class HeatsImageList_T12(ImageList):
    _label_cls = HeatsLabelList_T12

    def open(self, item):
        return super().open(self.path/(item[0]+".png"))

    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(9,10), **kwargs):

        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        #pdb.set_trace()
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows,rows,figsize=figsize)
        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):
            xs[i].show(ax=ax, y=ys[i], **kwargs)
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):
        """Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.
        `kwargs` are passed to the show method."""
        #pdb.set_trace()
        figsize = ifnone(figsize, (6,3*len(xs)))
        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)
        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)
        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):
            x.show(ax=axs[i,0], y=y, **kwargs)
            x.show(ax=axs[i,1], y=z, **kwargs)

    @classmethod
    def from_list(cls, imagelist, path=".", **kwargs):
        return cls(imagelist, path=Path(path), **kwargs)

class HeatsImageList_X3(ImageList):
    _label_cls = HeatsLabelList_3

    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(9,10), **kwargs):

        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        #pdb.set_trace()
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows,rows,figsize=figsize)
        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):
            xs[i].show(ax=ax, y=ys[i], **kwargs)
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):
        """Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.
        `kwargs` are passed to the show method."""
        #pdb.set_trace()
        figsize = ifnone(figsize, (6,3*len(xs)))
        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)
        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)
        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):
            x.show(ax=axs[i,0], y=y, **kwargs)
            x.show(ax=axs[i,1], y=z, **kwargs)

class HeatsImageList_X2(ImageList):
    _label_cls = HeatsLabelList_2

    def open(self, item):
        return super().open(item)

    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(9,10), **kwargs):

        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        #pdb.set_trace()
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows,rows,figsize=figsize)
        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):
            xs[i].show(ax=ax, y=ys[i], **kwargs)
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):
        """Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.
        `kwargs` are passed to the show method."""
        #pdb.set_trace()
        figsize = ifnone(figsize, (6,3*len(xs)))
        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)
        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)
        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):
            x.show(ax=axs[i,0], y=y, **kwargs)
            x.show(ax=axs[i,1], y=z, **kwargs)

    @classmethod
    def from_list(cls, imagelist, path=".", **kwargs):
        return cls(imagelist, path=Path(path), **kwargs)

class HeatsImageList_X(ImageList):
    _label_cls = HeatsLabelList

class HeatsImageList_X_SIMPLE(ImageList):
    _label_cls = HeatsLabelList_SIMPLE

class HeatsImageList_X0(ImageList):
    _label_cls = HeatsLabelList_0

    def open(self, item):
        return super().open(item)

    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(9,10), **kwargs):

        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        #pdb.set_trace()
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows,rows,figsize=figsize)
        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):
            xs[i].show(ax=ax, y=ys[i], **kwargs)
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):
        """Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.
        `kwargs` are passed to the show method."""
        #pdb.set_trace()
        figsize = ifnone(figsize, (6,3*len(xs)))
        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)
        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)
        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):
            x.show(ax=axs[i,0], y=y, **kwargs)
            x.show(ax=axs[i,1], y=z, **kwargs)

    @classmethod
    def from_list(cls, imagelist, path=".", **kwargs):
        return cls(imagelist, path=Path(path), **kwargs)

class HeatsImageList_0(ImageList):
    _label_cls = HeatsLabelList_0

    def open(self, item):
        return super().open(self.path/(item[0]+".png"))

    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(9,10), **kwargs):

        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        #pdb.set_trace()
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows,rows,figsize=figsize)
        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):
            xs[i].show(ax=ax, y=ys[i], **kwargs)
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):
        """Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.
        `kwargs` are passed to the show method."""
        #pdb.set_trace()
        figsize = ifnone(figsize, (6,3*len(xs)))
        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)
        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)
        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):
            x.show(ax=axs[i,0], y=y, **kwargs)
            x.show(ax=axs[i,1], y=z, **kwargs)

    @classmethod
    def from_list(cls, imagelist, path=".", **kwargs):
        return cls(imagelist, path=Path(path), **kwargs)

class HeatsImageList_3(ImageList):
    _label_cls = HeatsLabelList_3

    def open(self, item):
        return super().open(self.path/(item[0]+".png"))

    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(9,10), **kwargs):

        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        #pdb.set_trace()
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows,rows,figsize=figsize)
        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):
            xs[i].show(ax=ax, y=ys[i], **kwargs)
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):
        """Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.
        `kwargs` are passed to the show method."""
        #pdb.set_trace()
        figsize = ifnone(figsize, (6,3*len(xs)))
        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)
        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)
        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):
            x.show(ax=axs[i,0], y=y, **kwargs)
            x.show(ax=axs[i,1], y=z, **kwargs)

    @classmethod
    def from_list(cls, imagelist, path=".", **kwargs):
        return cls(imagelist, path=Path(path), **kwargs)

class HeatsImageList_2(ImageList):
    _label_cls = HeatsLabelList_2

    def open(self, item):
        return super().open(self.path/(item[0]+".png"))

    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(9,10), **kwargs):

        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        #pdb.set_trace()
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows,rows,figsize=figsize)
        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):
            xs[i].show(ax=ax, y=ys[i], **kwargs)
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):
        """Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.
        `kwargs` are passed to the show method."""
        #pdb.set_trace()
        figsize = ifnone(figsize, (6,3*len(xs)))
        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)
        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)
        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):
            x.show(ax=axs[i,0], y=y, **kwargs)
            x.show(ax=axs[i,1], y=z, **kwargs)

    @classmethod
    def from_list(cls, imagelist, path=".", **kwargs):
        return cls(imagelist, path=Path(path), **kwargs)

class HeatsImageList(ImageList):
    _label_cls = HeatsLabelList

    def open(self, item):
        return super().open(self.path/(item[0]+".png"))

    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(9,10), **kwargs):

        "Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method."
        #pdb.set_trace()
        rows = int(math.sqrt(len(xs)))
        fig, axs = plt.subplots(rows,rows,figsize=figsize)
        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):
            xs[i].show(ax=ax, y=ys[i], **kwargs)
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):
        """Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.
        `kwargs` are passed to the show method."""
        #pdb.set_trace()
        figsize = ifnone(figsize, (6,3*len(xs)))
        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)
        fig.suptitle('Ground truth / Predictions', weight='bold', size=14)
        for i,(x,y,z) in enumerate(zip(xs,ys,zs)):
            x.show(ax=axs[i,0], y=y, **kwargs)
            x.show(ax=axs[i,1], y=z, **kwargs)

    @classmethod
    def from_list(cls, imagelist, path=".", **kwargs):
        return cls(imagelist, path=Path(path), **kwargs)

class HeatMaps(ItemBase):

    def __init__(self, heat_maps):
        self._heat_maps = heat_maps

    def clone(self):

        return self.__class__(self.heat_maps.clone())

    @property
    def heat_maps(self):
        return self._heat_maps

    @heat_maps.setter
    def heat_maps(self, d):
        self._heat_maps = d

    @property
    def data(self):
        return self.heat_maps

    @property
    def obj(self):
        return self.heat_maps

    def prepare_for_visual(self):
        return Image(torch.stack([torch.sum(self.heat_maps, 0) for i in range(3)]))

    def refine_verta_pos():
        pdb.set_trace()
        peaks = [get_peaks(np.array(heatmap)) for heatmap in self.heat_maps]


    def apply_tfms(self, tfms, **kwargs):
        #print(kwargs)

        new_heat = self.clone()

        new_tfms = []
        for tfm in tfms:
            if type(tfm.tfm) != fastai.vision.image.TfmLighting:
                new_tfms.append(tfm)

        new_heat.heat_maps =  torch.stack([
            Image(torch.stack([
                heatmap for i in range(3)]
            )).apply_tfms(new_tfms, do_resolve=False, size=kwargs["size"]).data[0,:,:] for heatmap in new_heat.heat_maps])

        return new_heat

    def show(self, ax:plt.Axes, **kwargs):
        ax.set_title("vertebra locations")

        #pdb.set_trace()

        for i, heatmap in enumerate(self.heat_maps):
            all_peaks = get_peaks(np.array(heatmap))
            if (len(all_peaks) > 0):

                peak = all_peaks[np.argmax(all_peaks[:,2]),0:2]
                ax.plot(peak[0], peak[1], 'b.')
                ax.text(peak[0]+5, peak[1]+1, heat_names[i], fontsize=11, color="red")




        #ax.imshow(torch.sum(self.heat_maps, 0), alpha=0.2)

    def __repr__(self):
        return f'{self.__class__.__name__} {tuple(self.heat_maps.shape)}'

class vanilla_UNet(nn.Module):
    def __init__(self, n_channels, n_classes, bilinear=False):
        super(vanilla_UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        factor = 2 if bilinear else 1
        self.down4 = Down(512, 1024 // factor)
        self.up1 = Up(1024, 512, bilinear)
        self.up2 = Up(512, 256, bilinear)
        self.up3 = Up(256, 128, bilinear)
        self.up4 = Up(128, 64 * factor, bilinear)
        self.outc = OutConv(64, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return logits

class DoubleConv(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""

    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """Downscaling with maxpool then double conv"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class Up(nn.Module):
    """Upscaling then double conv"""

    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()

        # if bilinear, use the normal convolutions to reduce the number of channels
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_channels, out_channels // 2, in_channels // 2)
        else:
            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels)


    def forward(self, x1, x2):
        x1 = self.up(x1)
        # input is CHW
        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])
        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])

        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        # if you have padding issues, see
        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a
        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)

def get_peaks(map_ori):
    thre1 = 0.01
    one_heatmap = gaussian_filter(map_ori, sigma=3)
    map_left = np.zeros(one_heatmap.shape)
    map_left[1:, :] = one_heatmap[:-1, :]
    map_right = np.zeros(one_heatmap.shape)
    map_right[:-1, :] = one_heatmap[1:, :]
    map_up = np.zeros(one_heatmap.shape)
    map_up[:, 1:] = one_heatmap[:, :-1]
    map_down = np.zeros(one_heatmap.shape)
    map_down[:, :-1] = one_heatmap[:, 1:]


    peaks_binary = np.logical_and.reduce(
        (one_heatmap >= map_left, one_heatmap >= map_right,
         one_heatmap >= map_up, one_heatmap >= map_down, one_heatmap > thre1))
    peaks = list(zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0]))  # note reverse
    peaks_with_score = np.array([x + (map_ori[x[1], x[0]],) for x in peaks])

    return peaks_with_score

def evaluate_results(output, target, heat_id, shape=(1,1), verta_pos_thres=0.2):
    d = []

    for dset in range(output.shape[0]):

        all_peaks_pred = get_peaks(np.array(output[dset,heat_id].detach().cpu()))
        all_peaks_target = get_peaks(np.array(target[dset,heat_id].detach().cpu()))

        if (len(all_peaks_pred) > 0) and (len(all_peaks_target) > 0):

            all_peaks_pred = all_peaks_pred[all_peaks_pred[:,2] > verta_pos_thres]
            all_peaks_target = all_peaks_target[all_peaks_target[:,2] > verta_pos_thres]

            if (len(all_peaks_pred) > 0) and (len(all_peaks_target) > 0):

                peak_pred = np.array(all_peaks_pred[np.argmax(all_peaks_pred[:,2]),0:2])
                peak_target = np.array(all_peaks_target[np.argmax(all_peaks_target[:,2]),0:2])

                peak_pred[0] = peak_pred[0] / shape[1]
                peak_target[0] = peak_target[0] / shape[1]

                peak_pred[1] = peak_pred[1] / shape[0]
                peak_target[1] = peak_target[1] / shape[0]

                d.append(math.sqrt((peak_pred[0]-peak_target[0])**2+(peak_pred[1]-peak_target[1])**2))

    if len(d) == 0:
        return np.array([])
    else:
        return np.array(d)

def get_verta_pos(heatmaps, thres=0.2):
    heat_dict = []
    for heatmap in heatmaps:
        all_peaks = get_peaks(np.array(heatmap.detach().cpu()))
        if len(all_peaks) > 0:
            all_peaks = all_peaks[all_peaks[:,2] > thres]
            if len(all_peaks) > 0:
                peak = all_peaks[np.argmax(all_peaks[:,2]),0:3]
                heat_dict.append(peak)
            else:
                heat_dict.append(None)
        else:
            heat_dict.append(None)
    return heat_dict

def distance(p1,p2):
    return np.sqrt(np.sum((p1-p2)**2))

def interpolate(path, num=11):
    from scipy.interpolate import interp1d
    f = interp1d(path[:, 1], path[:, 0])
    x = np.linspace(path[:, 1].min(), path[:, 1].max(), num=num, endpoint=True, dtype=np.float)
    y = f(x)
    return np.stack((x,y))

def calc_ap(data):
    #pdb.set_trace()
    intpol = interpolate(data[:,[5,6]], num=len(data)).T
    gap = intpol[1,0] - intpol[0,0]
    add_v = int((1-intpol[:,0].max())/ gap)
    if add_v == 0:
        return 1.0
    a = np.full(add_v,0, dtype=np.float)
    a[0] = intpol[:,0].max() + gap
    a[1:] = gap
    a = np.cumsum(a)
    a = np.stack([a,np.zeros(len(a))]).T
    new_precision = np.concatenate((intpol, a))
    return new_precision[:,1].mean()

def calc_abs_pixel_error(predictions, target, verta_pos_thres = 0.2):
    custom_metrics = ["all_m","all_std"]

    for heat_name in heat_names:
        custom_metrics.append(heat_name+"_m")
        custom_metrics.append(heat_name+"_std")

    heats = {}

    for heat_name in heat_names:
        heats[heat_name] = np.array([])

    for i,heat_name in enumerate(heat_names):
        d_r = evaluate_results(predictions, target, i, (1,1), verta_pos_thres)
        heats[heat_name] = np.concatenate((heats[heat_name],d_r))

    metrics = []

    all = np.array([])

    for heat_name in heat_names:
        all = np.concatenate((all,heats[heat_name]))

    metrics.append(all.mean())
    metrics.append(all.std())

    for heat_name in heat_names:
        metrics.append(heats[heat_name].mean())
        metrics.append(heats[heat_name].std())

    return np.swapaxes(np.concatenate((np.array(custom_metrics)[None], np.array(metrics)[None]), axis=0), 0,1), heats, all

def calc_rel_pixel_error(predictions, target, shape, verta_pos_thres = 0.2):
    custom_metrics = ["all_m","all_std"]

    for heat_name in heat_names:
        custom_metrics.append(heat_name+"_m")
        custom_metrics.append(heat_name+"_std")

    heats = {}

    for heat_name in heat_names:
        heats[heat_name] = np.array([])

    #pdb.set_trace()

    for i,heat_name in enumerate(heat_names):
        d_r = evaluate_results(predictions, target, i, shape, verta_pos_thres)
        heats[heat_name] = np.concatenate((heats[heat_name],d_r))

    metrics = []

    #pdb.set_trace()

    all = np.array([])

    for heat_name in heat_names:
        all = np.concatenate((all,heats[heat_name]))

    #pdb.set_trace()
    metrics.append(all.mean())
    metrics.append(all.std())

    for heat_name in heat_names:
        metrics.append(heats[heat_name].mean())
        metrics.append(heats[heat_name].std())

    return np.swapaxes(np.concatenate((np.array(custom_metrics)[None], np.array(metrics)[None]), axis=0), 0,1), heats, all

def calc_ap_pr_rc(predictions, target, verta_pos_thres=0.2):
    #pdb.set_trace()

    fps_distances=[]
    tps_distances=[]
    custom_metrics = ["mAP", "mPR", "mRC"]
    for heat_name in heat_names:
        custom_metrics.append(heat_name+"_pr")
        custom_metrics.append(heat_name+"_rc")
        custom_metrics.append(heat_name+"_ap")

    #pdb.set_trace()

    metric_pos = {item : i for i,item in enumerate(custom_metrics)}

    all_predictions = {}
    for heat in heat_names:
        all_predictions[heat] = [[],0,0]

    #pdb.set_trace()

    all_tp_perc_in_image = []
    all_fp_perc_in_image = []
    only_fp_perc_in_image = []
    only_tp_perc_in_image = []
    for predict, target in zip(predictions, target):
        # transform heatmaps into points
        vertas_pred = get_verta_pos(predict, verta_pos_thres)
        vertas_grt = get_verta_pos(target, verta_pos_thres)

        #pdb.set_trace()
        tp_in_predict = 0
        gt_count = 0
        # measure true positves / false positives
        for item in list(zip(vertas_pred, vertas_grt, heat_names, heat_sizes)):
            if (item[0] is not None):
                all_predictions[item[2]][1] += 1 # pred count
                tp = False
                if (item[1] is not None):
                    dist = distance(item[0][0:2], item[1][0:2])
                    if (dist <= ((item[3]/2))):
                        tp = True
                        tp_in_predict += 1
                        tps_distances.append(dist)
                    else:
                        fps_distances.append(dist)

                all_predictions[item[2]][0].append([item[0][2],int(tp), int(not tp), 0, 0, 0, 0])
            if (item[1] is not None):
                gt_count += 1
                all_predictions[item[2]][2] += 1 # target count

        all_tp_perc_in_image.append(tp_in_predict/gt_count)
        all_fp_perc_in_image.append((gt_count - tp_in_predict)/gt_count)

        if tp_in_predict > 0:
            only_tp_perc_in_image.append(tp_in_predict/gt_count)

        if (gt_count - tp_in_predict) > 0:
            only_fp_perc_in_image.append((gt_count - tp_in_predict)/gt_count)


        metrics = list(np.zeros(len(custom_metrics), dtype=int))

    #pdb.set_trace()

    # sort confidence descenting
    for key in all_predictions.keys():
        all_predictions[key][0] = np.array(all_predictions[key][0])
        if len(all_predictions[key][0]) > 0:
            all_predictions[key][0] = all_predictions[key][0][all_predictions[key][0][:,0].argsort()[::-1]]

    #pdb.set_trace()

    # acumulated sum of TP and FP
    for key in all_predictions.keys():
        if len(all_predictions[key][0]) > 0:
            # TP
            all_predictions[key][0][:,3] = np.cumsum(all_predictions[key][0][:,1])
            # FP
            all_predictions[key][0][:,4] = np.cumsum(all_predictions[key][0][:,2])

    #pdb.set_trace()

    # calculate precision and recall
    for key in all_predictions.keys():
        if len(all_predictions[key][0]) > 0:
            # precision
            all_predictions[key][0][:,5] = all_predictions[key][0][:,3] / (all_predictions[key][0][:,3] + all_predictions[key][0][:,4])
            # recall
            all_predictions[key][0][:,6] = all_predictions[key][0][:,3] / all_predictions[key][2]

    #pdb.set_trace()

    # add all to metrics
    aps = []
    rcs = []
    prc = []
    for key in all_predictions.keys():

        if len(all_predictions[key][0]) > 0:
            try:
                # precision
                pr = all_predictions[key][0][-1,5]
                metrics[metric_pos[key+"_pr"]] = pr
                prc.append(pr)
            except:
                prc.append(0)

            try:
                # recall
                rc = all_predictions[key][0][-1,6]
                metrics[metric_pos[key+"_rc"]] = rc
                rcs.append(rc)
            except:
                rcs.append(0)

            try:
                # average precision
                ap = calc_ap(all_predictions[key][0])
                metrics[metric_pos[key+"_ap"]] = ap
                aps.append(ap)
            except:
                aps.append(0)

        else:
            prc.append(0)
            rcs.append(0)
            aps.append(0)

    metrics[metric_pos["mAP"]] = np.array(aps).mean()
    metrics[metric_pos["mPR"]] = np.array(prc).mean()
    metrics[metric_pos["mRC"]] = np.array(rcs).mean()

    return np.swapaxes(np.concatenate((np.array(custom_metrics)[None], np.array(metrics)[None]), axis=0), 0,1),np.array(fps_distances), np.array(tps_distances),np.array(all_tp_perc_in_image),np.array(all_fp_perc_in_image),np.array(only_tp_perc_in_image),np.array(only_fp_perc_in_image)

class mean_average_precision_metric(LearnerCallback):
    _order=-20 # Needs to run before the recorder
    def __init__(self, learn, net_file_prefix="", metric_counter=5, save_counter=5,
                 scale_factor=1, inner_heat_names=None, inner_heat_sizes=None):
        super().__init__(learn)
        self.net_file_prefix = net_file_prefix
        self.metric_counter = metric_counter
        self.scale_factor = scale_factor
        self.save_counter = save_counter
        if inner_heat_names is None:
            self.heat_names = heat_names
        else:
            self.heat_names = inner_heat_names

        if inner_heat_sizes is None:
            self.heat_sizes = heat_sizes
        else:
            self.heat_sizes = inner_heat_sizes

    def on_train_begin(self, **kwargs):
        self.c_e = 0

        self.custom_metrics = ["mAP_t", "mAP_v", "pr_t", "pr_v", "rc_t", "rc_v"]
        for heat_name in self.heat_names:
            self.custom_metrics.append(heat_name+"_pr_t")
            self.custom_metrics.append(heat_name+"_rc_t")
            self.custom_metrics.append(heat_name+"_ap_t")
            self.custom_metrics.append(heat_name+"_pr_v")
            self.custom_metrics.append(heat_name+"_rc_v")
            self.custom_metrics.append(heat_name+"_ap_v")

        self.metric_pos = {item : i for i,item in enumerate(self.custom_metrics)}

        self.learn.recorder.add_metric_names(self.custom_metrics.copy())


    def on_batch_end(self, last_output, last_target, **kwargs):

        if self.c_e % self.metric_counter == 0:

            for predict, target in zip(last_output, last_target):
                # transform heatmaps into points
                vertas_pred = get_verta_pos(predict)
                vertas_grt = get_verta_pos(target)

                # measure true positves / false positives

                pred_temp = self.all_predictions_t if kwargs['train'] == True else self.all_predictions_v

                for item in list(zip(vertas_pred, vertas_grt, self.heat_names, self.heat_sizes)):
                    if (item[0] is not None):
                        pred_temp[item[2]][1] += 1 # pred count
                        tp = False
                        if (item[1] is not None) and (distance(item[0][0:2], item[1][0:2]) <= ((item[3]/2)*self.scale_factor)):
                            tp = True
                        pred_temp[item[2]][0].append([item[0][2],int(tp), int(not tp), 0, 0, 0, 0])
                    if (item[1] is not None):
                        pred_temp[item[2]][2] += 1 # target count

                if kwargs['train'] == True:
                    self.all_predictions_t = pred_temp
                else:
                    self.all_predictions_v= pred_temp



    def on_epoch_begin(self, **kwargs):
        if self.c_e % self.metric_counter == 0:

            self.all_predictions_t = {}
            self.all_predictions_v = {}
            for heat in self.heat_names:
                self.all_predictions_t[heat] = [[],0,0]
                self.all_predictions_v[heat] = [[],0,0]


    def on_epoch_end(self, last_metrics, **kwargs):

        #if self.c_e % self.save_counter == 0:
            #self.save(self.net_file_prefix + str(self.c_e))

        if self.c_e % self.metric_counter == 0:

            metrics = list(np.zeros(len(self.custom_metrics), dtype=int))

            #pdb.set_trace()
            for predict, suffix in zip([self.all_predictions_t, self.all_predictions_v], ["_t", "_v"]):


                # sort confidence descenting
                for key in predict.keys():
                    predict[key][0] = np.array(predict[key][0])
                    if len(predict[key][0]) > 0:
                        predict[key][0] = predict[key][0][predict[key][0][:,0].argsort()[::-1]]

                # acumulated sum of TP and FP
                for key in predict.keys():
                    if len(predict[key][0]) > 0:
                        # TP
                        predict[key][0][:,3] = np.cumsum(predict[key][0][:,1])
                        # FP
                        predict[key][0][:,4] = np.cumsum(predict[key][0][:,2])

                # calculate precision and recall
                for key in predict.keys():
                    if len(predict[key][0]) > 0:
                        # precision
                        predict[key][0][:,5] = predict[key][0][:,3] / (predict[key][0][:,3] + predict[key][0][:,4])
                        # recall
                        predict[key][0][:,6] = predict[key][0][:,3] / predict[key][2]

                # add all to fastai metrics
                aps = []
                rcs = []
                prc = []
                for key in predict.keys():
                    if len(predict[key][0]) > 0:
                        try:
                            # precision
                            pr = predict[key][0][-1,5]
                            metrics[self.metric_pos[key+"_pr"+suffix]] = pr
                            prc.append(pr)
                        except:
                            prc.append(0)

                        try:
                            # recall
                            rc = predict[key][0][-1,6]
                            metrics[self.metric_pos[key+"_rc"+suffix]] = rc
                            rcs.append(rc)
                        except:
                            rcs.append(0)

                        try:
                            # average precision
                            ap = calc_ap(predict[key][0])
                            metrics[self.metric_pos[key+"_ap"+suffix]] = ap
                            aps.append(ap)
                        except:
                            aps.append(0)

                    else:
                        prc.append(0)
                        rcs.append(0)
                        aps.append(0)

                metrics[self.metric_pos["mAP"+suffix]] = np.array(aps).mean()
                metrics[self.metric_pos["pr"+suffix]] = np.array(prc).mean()
                metrics[self.metric_pos["rc"+suffix]] = np.array(rcs).mean()

        else:
            metrics = list(np.zeros(len(self.custom_metrics), dtype=int))

        self.c_e += 1

        for metric in metrics:
            metric = str(round(metric, 2))

        return add_metrics(last_metrics, (metrics))

def predict_vertebrae_position(image, learn, threshold=0.6):
    vertebrae_positions = {}
    batch = learn.data.one_item(image)
    res = learn.pred_batch(batch=batch)

    for i, vertebrae in enumerate(heat_names):
        vertebrae_positions[vertebrae] = None
        #p = np.flip(np.unravel_index(res[0,i].argmax(), res[0,i].shape))
        #if res[0,i][p[1],p[0]]>threshold

        all_peaks_pred = get_peaks(res[0,i])
        #pdb.set_trace()
        if (len(all_peaks_pred) > 0):
            all_peaks_pred = all_peaks_pred[all_peaks_pred[:,2] > threshold]
            if len(all_peaks_pred) > 0:
                vertebrae_positions[vertebrae] = all_peaks_pred
            #if with_confidence:

            #else:
                #vertebrae_positions[vertebrae] = all_peaks_pred[:,0:2]
                #np.argmax(all_peaks_pred[:,2])
    #pdb.set_trace()
    #if refine_results:
    return do_refine_results(vertebrae_positions)
    #else:
        #return vertebrae_positions

def do_refine_results(vertebrae_positions):
    #pdb.set_trace()
    final_vertas = {}
    first = True
    pre_key = None
    dist_treshold = 5
    #pdb.set_trace()
    for key in vertebrae_positions.keys():
        #if key=="T8":
            #pdb.set_trace()
        #try:
        final_vertas[key] = None
        if vertebrae_positions[key] is not None:
            if first:
                final_vertas[key] = vertebrae_positions[key][np.argmax(vertebrae_positions[key][:,2])]
                first = False
            else:
                dists = np.sqrt(np.sum(((vertebrae_positions[key][:,0:2] - final_vertas[pre_key][0:2])**2),axis=1))
                dists_sorted = np.argsort(dists)
                for dist_srt in dists_sorted:
                    if dists[dist_srt] > dist_treshold:
                        idx = dists_sorted[dist_srt]
                        final_vertas[key] = vertebrae_positions[key][idx]

                        break
        if final_vertas[key] is not None:
            pre_key = key
        #except:
            #pdb.set_trace()
    return final_vertas

def o_p_acc(input, target):
    target_squeeze = target.squeeze(1)
    out = (input.argmax(dim=1) == target_squeeze).float().mean()
    return out

class waist_pixel_accuracy(LearnerCallback):
    _order=-20 # Needs to run before the recorder

    def __init__(self, learn):
        super().__init__(learn)

    def on_train_begin(self, **kwargs):
        self.learn.recorder.add_metric_names(['t_lw_p_ac', 't_rw_p_ac', 'v_lw_p_ac', 'v_rw_p_ac'])

    def on_batch_end(self, last_output, last_target, **kwargs):


        def label_pixel_accuracy(input, target, label):
            input, target = set_mask_for_label(input, target, label)

            same_fields = np.logical_and(target, input)
            ac = []
            for i in range(input.shape[0]):
                ac.append(len(np.where(same_fields[i] == 1)[0]) / len(np.where(target[i] == 1)[0]))

            #return tensor(np.array(ac).mean())
            return np.array(ac).mean()

        if kwargs['train'] == True:
            self.train_lw_acc.append(label_pixel_accuracy(last_output, last_target, lw_l))
            self.train_rw_acc.append(label_pixel_accuracy(last_output, last_target, rw_l))
        else:
            self.valid_lw_acc.append(label_pixel_accuracy(last_output, last_target, lw_l))
            self.valid_rw_acc.append(label_pixel_accuracy(last_output, last_target, rw_l))

    def on_epoch_begin(self, **kwargs):
        self.train_lw_acc = []
        self.train_rw_acc = []
        self.valid_lw_acc = []
        self.valid_rw_acc = []

    def on_epoch_end(self, last_metrics, **kwargs):

        return add_metrics(last_metrics, [np.array(self.train_lw_acc).mean(),
                                          np.array(self.train_rw_acc).mean(),
                                          np.array(self.valid_lw_acc).mean(),
                                          np.array(self.valid_rw_acc).mean()])

class waist_curve_accuracy(LearnerCallback):
    _order=-20 # Needs to run before the recorder

    def __init__(self, learn):
        super().__init__(learn)

    def on_train_begin(self, **kwargs):

        self.c_e = 0

        self.learn.recorder.add_metric_names(['t_lw_shift', 't_rw_shift',
                                              't_lw_er_proc', 't_rw_er_proc', 't_lw_er_after', 't_lw_er_after',
                                              't_lw_er_before', 't_rw_er_before',

                                              'v_lw_shift', 'v_rw_shift',
                                              'v_lw_er_proc', 'v_rw_er_proc', 'v_lw_er_after', 'v_rw_er_after',
                                              'v_lw_er_before', 'v_rw_er_before'])

    def on_batch_end(self, last_output, last_target, **kwargs):

        def label_curve_accuracy(input, target, label):
            input, target = set_mask_for_label(input, target, label)

            ers=[]
            translations=[]
            er_before=[]
            er_after=[]



            for i in range(input.shape[0]):
                try:
                    input_skel = skeletonize(input[i]).astype(np.uint8)
                    target_skel = skeletonize(target[i]).astype(np.uint8)

                    input_points = np.array(np.where(input_skel)).T
                    input_points[:,0], input_points[:,1] = input_points[:,1], input_points[:,0].copy()

                    target_points = np.array(np.where(target_skel)).T
                    target_points[:,0], target_points[:,1] = target_points[:,1], target_points[:,0].copy()

                    if input_points[0,1] == input_points[1,1]:
                        input_points[0,1] = input_points[0,1] - 1

                    if target_points[0,1] == target_points[1,1]:
                        target_points[0,1] = target_points[0,1] - 1


                    input_points_int = interpolate_v1(input_points)

                    target_points_int = interpolate_v1(target_points)

                    er, input_trans, trans = procrustes_analysis(target_points_int, input_points_int)

                    ers.append(er)
                    translations.append(np.linalg.norm(trans['translation']))
                    er_after.append(np.abs(input_trans - target_points_int).mean())
                    er_before.append(np.abs(input_points_int - target_points_int).mean())
                except:
                    continue


            return np.array(ers).mean(), np.array(translations).mean(), np.array(er_after).mean(), np.array(er_before).mean()


        er_pr_lw, trans_lw, er_after_lw, er_before_lw = label_curve_accuracy(last_output, last_target, lw_l)
        er_pr_rw, trans_rw, er_after_rw, er_before_rw = label_curve_accuracy(last_output, last_target, rw_l)


        if kwargs['train'] == True:
            self.t_lw_shift.append(trans_lw)
            self.t_rw_shift.append(trans_rw)
            self.t_lw_er_proc.append(er_pr_lw)
            self.t_rw_er_proc.append(er_pr_rw)
            self.t_lw_er_after.append(er_after_lw)
            self.t_rw_er_after.append(er_after_rw)
            self.t_lw_er_before.append(er_before_lw)
            self.t_rw_er_before.append(er_before_rw)
        else:
            self.v_lw_shift.append(trans_lw)
            self.v_rw_shift.append(trans_rw)
            self.v_lw_er_proc.append(er_pr_lw)
            self.v_rw_er_proc.append(er_pr_rw)
            self.v_lw_er_after.append(er_after_lw)
            self.v_rw_er_after.append(er_after_rw)
            self.v_lw_er_before.append(er_before_lw)
            self.v_rw_er_before.append(er_before_rw)


    def on_epoch_begin(self, **kwargs):
        self.t_lw_shift = []
        self.t_rw_shift = []
        self.t_lw_er_proc = []
        self.t_rw_er_proc = []
        self.t_lw_er_after = []
        self.t_rw_er_after = []
        self.t_lw_er_before = []
        self.t_rw_er_before = []

        self.v_lw_shift = []
        self.v_rw_shift = []
        self.v_lw_er_proc = []
        self.v_rw_er_proc = []
        self.v_lw_er_after = []
        self.v_rw_er_after = []
        self.v_lw_er_before = []
        self.v_rw_er_before = []


    def on_epoch_end(self, last_metrics, **kwargs):
        if self.c_e % 10 == 0:
            filename = 'stage-resnet34-256-16-'+ str(self.c_e)
            self.save(filename)
            print(filename,"saved")

        self.c_e += 1

        return add_metrics(last_metrics, [np.array(self.t_lw_shift).mean(),
                                          np.array(self.t_rw_shift).mean(),
                                          np.array(self.t_lw_er_proc).mean(),
                                          np.array(self.t_rw_er_proc).mean(),
                                          np.array(self.t_lw_er_after).mean(),
                                          np.array(self.t_rw_er_after).mean(),
                                          np.array(self.t_lw_er_before).mean(),
                                          np.array(self.t_rw_er_before).mean(),

                                          np.array(self.v_lw_shift).mean(),
                                          np.array(self.v_rw_shift).mean(),
                                          np.array(self.v_lw_er_proc).mean(),
                                          np.array(self.v_rw_er_proc).mean(),
                                          np.array(self.v_lw_er_after).mean(),
                                          np.array(self.v_rw_er_after).mean(),
                                          np.array(self.v_lw_er_before).mean(),
                                          np.array(self.v_rw_er_before).mean()])



def mask_to_points(inputs):
    points = {}
    labels = ["left", "right"]
    for label,l_name in enumerate(labels):
        input = set_mask_for_label(inputs.copy(), label+1)

        input_skel = skeletonize(input).astype(np.uint8)

        input_points = np.array(np.where(input_skel)).T
        input_points[:,0], input_points[:,1] = input_points[:,1], input_points[:,0].copy()

        if input_points[0,1] == input_points[1,1]:
            input_points[0,1] = input_points[0,1] - 1

        input_points_int = interpolate(input_points).tolist()
        points[l_name] = input_points_int
    return points

def interpolate_v1(path, num=20, debug=False):
    from scipy.interpolate import interp1d

    f = interp1d(path[:, 1], path[:, 0])
    x = np.linspace(path[:, 1].min(), path[:, 1].max(), num=num,
                    endpoint=True, dtype=np.float)
    x = np.round(x).astype(np.int)
    y = np.round(f(x)).astype(np.int)
    out = np.concatenate((np.reshape(x,(x.shape[0],1)),np.reshape(y,(y.shape[0],1))), axis=1)

    out[:, 0], out[:, 1] = out[:, 1], out[:, 0].copy()
    return out

def predict_line(image, learn):
    prediction = learn.predict(image)[0]
    return mask_to_points(np.array(torch.squeeze(prediction.data)))

def read_image_from_dataframe(df, img):
    image = np.array(df[img].iloc[0], dtype=np.float32).reshape(500,500,3)
    image = np.swapaxes(np.swapaxes(image,0,2), 1,2)
    image = (image-np.min(image))/(np.max(image)-np.min(image))
    return Image(tensor(image))

class rel_pixel_error_metric(LearnerCallback):
    _order=-20 # Needs to run before the recorder

    def __init__(self, learn, metric_counter=5, shape=(500,200)):
        super().__init__(learn)
        self.metric_counter = metric_counter
        self.shape = shape

    def on_train_begin(self, **kwargs):
        self.c_e = 0

        self.custom_metrics = ["all_t_m","all_t_std","all_v_m","all_v_std"]

        for heat_name in heat_names:
            self.custom_metrics.append(heat_name+"_t_m")
            self.custom_metrics.append(heat_name+"_t_std")
            self.custom_metrics.append(heat_name+"_v_m")
            self.custom_metrics.append(heat_name+"_v_std")

        self.learn.recorder.add_metric_names(self.custom_metrics.copy())

    def on_batch_end(self, last_output, last_target, **kwargs):


        if self.c_e % self.metric_counter == 0:
            #if self.c_e > 1:
                #pdb.set_trace()

            if kwargs['train'] == True:
                for i,heat_name in enumerate(heat_names):
                    d_r = evaluate_results(last_output, last_target, i, self.shape)
                    self.train_heats[heat_name+"_t"] = np.concatenate((self.train_heats[heat_name+"_t"],d_r))

            else:
                for i,heat_name in enumerate(heat_names):
                    d_r = evaluate_results(last_output, last_target, i, self.shape)
                    self.valid_heats[heat_name+"_v"] = np.concatenate((self.valid_heats[heat_name+"_v"],d_r))


    def on_epoch_begin(self, **kwargs):
        if self.c_e % self.metric_counter == 0:
            self.train_heats = {}
            self.valid_heats = {}
            for heat_name in heat_names:
                self.train_heats[heat_name+"_t"] = np.array([])
                self.valid_heats[heat_name+"_v"] = np.array([])

    def on_epoch_end(self, last_metrics, **kwargs):
        if self.c_e % self.metric_counter == 0:

            #if self.c_e > 1:
                #pdb.set_trace()
            metrics = []

            all_t = np.array([])
            all_v = np.array([])
            for heat_name in heat_names:
                all_t = np.concatenate((all_t,self.train_heats[heat_name + "_t"]))
                all_v = np.concatenate((all_v,self.valid_heats[heat_name + "_v"]))

            metrics.append(all_t.mean())
            metrics.append(all_t.std())
            metrics.append(all_v.mean())
            metrics.append(all_v.std())

            for heat_name in heat_names:
                metrics.append(self.train_heats[heat_name + "_t"].mean())
                metrics.append(self.train_heats[heat_name + "_t"].std())
                metrics.append(self.valid_heats[heat_name + "_v"].mean())
                metrics.append(self.valid_heats[heat_name + "_v"].std())
        else:
            metrics = list(np.zeros(len(self.custom_metrics), dtype=int))

        self.c_e += 1

        return add_metrics(last_metrics, metrics)